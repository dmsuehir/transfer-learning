{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35836c9",
   "metadata": {},
   "source": [
    "# Transfer Learning for Image Classification\n",
    "\n",
    "This notebook uses [ViT](https://huggingface.co/google/vit-base-patch16-224-in21k) classifier model from ðŸ¤— model hub that was originally trained using [ImageNet](https://image-net.org) and does transfer learning with [Food101](https://huggingface.co/datasets/food101) dataset from ðŸ¤— Datasets.\n",
    "The notebook performs the following steps:\n",
    "1. [Import dependencies and setup parameters](#1.-Import-dependencies-and-setup-parameters)\n",
    "2. [Load the Food101 dataset](#2.-Load-the-Food101-dataset)\n",
    "3. [Preprocess the dataset](#3.-Preprocess-the-dataset)\n",
    "4. [Transfer Learning](#4.-Transfer-Learning)\n",
    "5. [Predict on test subset](#5.-Predict-on-test-subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4572dea",
   "metadata": {},
   "source": [
    "## 1. Import dependencies and setup parameters\n",
    "\n",
    "This notebook assumes that you have already followed the instructions in the [README.md](/notebooks/README.md) to setup a ðŸ¤— transformers environment with all the dependencies required to run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebba765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "# -------\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from tlt.utils.platform_util import PlatformUtil, OptimizedPlatformUtil\n",
    "\n",
    "\n",
    "# Huggingface\n",
    "# -----------\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    DefaultDataCollator,\n",
    "    AutoModelForImageClassification,\n",
    "    TFAutoModelForImageClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    create_optimizer,\n",
    "    pipeline\n",
    ")\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "import evaluate\n",
    "\n",
    "\n",
    "# PyTorch\n",
    "# -------\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "# TensorFlow\n",
    "# ----------\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27af490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the the parent directory for the custom or Torchvision dataset\n",
    "dataset_directory = os.environ[\"DATASET_DIR\"] if \"DATASET_DIR\" in os.environ else \\\n",
    "    os.path.join(os.environ[\"HOME\"], \"dataset\")\n",
    "    \n",
    "# Specify a directory for output\n",
    "output_directory = os.environ[\"OUTPUT_DIR\"] if \"OUTPUT_DIR\" in os.environ else \\\n",
    "    os.path.join(os.environ[\"HOME\"], \"output\")\n",
    "\n",
    "print(\"Dataset directory:\", dataset_directory)\n",
    "print(\"Output directory:\", output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4281a5",
   "metadata": {},
   "source": [
    "### (Optional) Optimized CPU platform\n",
    "\n",
    "This step uses TLT's `OptimizedPlatformUtil` to set certain environment variables for TensorFlow and PyTorch to recommended values for optimized model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6aa15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = PlatformUtil()\n",
    "OptimizedPlatformUtil(\n",
    "    omp_num_threads=pl.cores,\n",
    "    kmp_blocktime=0,\n",
    "    kmp_affinity=\"granularity=fine,compact,1,0\",\n",
    "    tf_num_intraop_threads=pl.cores_per_socket,\n",
    "    tf_num_interop_threads=pl.sockets,\n",
    "    force_reset_env_vars=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb2e91f",
   "metadata": {},
   "source": [
    "## 2. Load the Food101 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aabc83",
   "metadata": {},
   "source": [
    "**Note:** In this notebook, we will load a subset of 5000 train samples from Food101 dataset. You can modify the `split` arg in the `load_dataset()` as you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff09cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a subset of Food101 dataset\n",
    "dataset = load_dataset('food101', split='train[:5000]', cache_dir=dataset_directory)\n",
    "\n",
    "# Split the dataset for training and evaluation\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# Define variables to hold labels and their mappings\n",
    "labels = dataset[\"train\"].features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "# Assign different variables for different frameworks\n",
    "dataset_for_pyt = dataset\n",
    "dataset_for_tf = dataset\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7618f24",
   "metadata": {},
   "source": [
    "### Inspect the dataset\n",
    "\n",
    "Select a random image from the dataset and see how it actually represented in the dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e0b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "select_num = random.randint(0, len(labels) - 1)\n",
    "\n",
    "img_dict = dataset['train'][select_num]\n",
    "\n",
    "print(img_dict)\n",
    "print(id2label[str(img_dict['label'])])\n",
    "img_dict['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56777018",
   "metadata": {},
   "source": [
    "# 3. Preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1969b791",
   "metadata": {},
   "source": [
    "Run below cell which gets the matching image preprocessor for chosen model. This step is common for both PyTorch and TensorFlow frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f980a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/vit-base-patch16-224-in21k\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "image_processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d69eaf",
   "metadata": {},
   "source": [
    "### Option A: PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a700b7b3",
   "metadata": {},
   "source": [
    "If using PyTorch as a backend, use the torch transforms to apply preprocessing to the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc4c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    ")\n",
    "\n",
    "# Define your transforms\n",
    "_transforms = T.Compose([\n",
    "    T.RandomResizedCrop(size), \n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "])\n",
    "\n",
    "# Apply the transforms to the dataset\n",
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "    return examples\n",
    "\n",
    "dataset_for_pyt = dataset_for_pyt.with_transform(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445cee2",
   "metadata": {},
   "source": [
    "Skip to next step [4. Transfer Learning](#4.-Transfer-Learning) to continue using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7180f562",
   "metadata": {},
   "source": [
    "### Option B: TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14e92e7",
   "metadata": {},
   "source": [
    "If using TensorFlow as a backend, use the keras layers to apply preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97690ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    "\n",
    "# Define your keras layers for preprocessing\n",
    "train_data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomCrop(size[0], size[1]),\n",
    "        layers.Rescaling(scale=1.0 / 127.5, offset=-1),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "    ],\n",
    "    name=\"train_data_augmentation\",\n",
    ")\n",
    "\n",
    "val_data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.CenterCrop(size[0], size[1]),\n",
    "        layers.Rescaling(scale=1.0 / 127.5, offset=-1),\n",
    "    ],\n",
    "    name=\"val_data_augmentation\",\n",
    ")\n",
    "\n",
    "# Define helper functions to apply preprocessing layers\n",
    "def convert_to_tf_tensor(image: Image):\n",
    "    np_image = np.array(image)\n",
    "    tf_image = tf.convert_to_tensor(np_image)\n",
    "    # `expand_dims()` is used to add a batch dimension since\n",
    "    # the TF augmentation layers operates on batched inputs.\n",
    "    return tf.expand_dims(tf_image, 0)\n",
    "\n",
    "\n",
    "def preprocess_train(example_batch):\n",
    "    \"\"\"Apply train_transforms across a batch.\"\"\"\n",
    "    images = [\n",
    "        train_data_augmentation(convert_to_tf_tensor(image.convert(\"RGB\"))) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    example_batch[\"pixel_values\"] = [tf.transpose(tf.squeeze(image)) for image in images]\n",
    "    return example_batch\n",
    "\n",
    "\n",
    "def preprocess_val(example_batch):\n",
    "    \"\"\"Apply val_transforms across a batch.\"\"\"\n",
    "    images = [\n",
    "        val_data_augmentation(convert_to_tf_tensor(image.convert(\"RGB\"))) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    example_batch[\"pixel_values\"] = [tf.transpose(tf.squeeze(image)) for image in images]\n",
    "    return example_batch\n",
    "\n",
    "# Set the helper methods to the dataset(s)\n",
    "dataset_for_tf[\"train\"].set_transform(preprocess_train)\n",
    "dataset_for_tf[\"test\"].set_transform(preprocess_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb36e88",
   "metadata": {},
   "source": [
    "## 4. Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79938eff",
   "metadata": {},
   "source": [
    "### Option A: PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e64f480",
   "metadata": {},
   "source": [
    "If using PyTorch as a backend, get the model from ðŸ¤— Auto... class and use ðŸ¤— Trainer to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "\n",
    "# Define a function to calculate accuracy\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Define training args for the Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_directory,\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Define the Trainer class\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=DefaultDataCollator(),\n",
    "    train_dataset=dataset_for_pyt[\"train\"],\n",
    "    eval_dataset=dataset_for_pyt[\"test\"],\n",
    "    tokenizer=image_processor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.train()  # Puts the model in training mode\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbfd409",
   "metadata": {},
   "source": [
    "### Option B: TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ef0d3",
   "metadata": {},
   "source": [
    "If using TensorFlow as a backend, get the model from ðŸ¤— TFAuto... class and use the TensorFlow's `fit()` method to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac4b46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = TFAutoModelForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "\n",
    "# Convert ðŸ¤— Dataset to tf.data.Dataset\n",
    "batch_size = 16\n",
    "tf_train_dataset = dataset_for_tf[\"train\"].to_tf_dataset(\n",
    "    columns=\"pixel_values\", label_cols=\"label\", shuffle=True, batch_size=batch_size,\n",
    "    collate_fn=DefaultDataCollator(return_tensors=\"tf\")\n",
    ")\n",
    "\n",
    "# converting our test dataset to tf.data.Dataset\n",
    "tf_eval_dataset = dataset_for_tf[\"test\"].to_tf_dataset(\n",
    "    columns=\"pixel_values\", label_cols=\"label\", shuffle=True, batch_size=batch_size,\n",
    "    collate_fn=DefaultDataCollator(return_tensors=\"tf\")\n",
    ")\n",
    "\n",
    "\n",
    "# Define a function to calculate accuracy\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "# Create optimizer\n",
    "num_epochs = 2\n",
    "num_train_steps = len(dataset[\"train\"]) * num_epochs\n",
    "learning_rate = 3e-5\n",
    "weight_decay_rate = 0.01\n",
    "\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=weight_decay_rate,\n",
    "    num_warmup_steps=0,\n",
    ")\n",
    "\n",
    "# Define loss and callbacks\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "callbacks = [KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_eval_dataset)]\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "# Train the model\n",
    "model.fit(tf_train_dataset, validation_data=tf_eval_dataset, epochs=num_epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e79e82",
   "metadata": {},
   "source": [
    "## 5. Predict on test subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4ae89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_predictions(image, model, framework):\n",
    "    model_input = image_processor(\n",
    "        image,\n",
    "        return_tensors = 'tf' if framework == 'tensorflow' else 'pt'\n",
    "    )\n",
    "    if framework == 'tensorflow':\n",
    "        logits = model(**model_input).logits\n",
    "        predicted_class_id = int(tf.math.argmax(logits, axis=-1)[0])\n",
    "    if framework == 'pytorch':\n",
    "        with torch.no_grad():\n",
    "            logits = model(**model_input).logits\n",
    "        predicted_class_id = logits.argmax(-1).item()\n",
    "    return predicted_class_id\n",
    "\n",
    "selected_image_indices = random.sample(range(0, dataset['test'].num_rows), 30)\n",
    "selected_images = []\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "for s in tqdm(selected_image_indices):\n",
    "    img = dataset['test'][s]['image']\n",
    "    label = dataset['test'][s]['label']\n",
    "    selected_images.append(img)\n",
    "    true_labels.append(label)\n",
    "    predicted_labels.append(get_predictions(img, model, 'pytorch' if isinstance(model, torch.nn.Module) else 'tensorflow'))\n",
    "    \n",
    "# Visualize the predictions\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for n in range(30):\n",
    "    plt.subplot(6,5,n+1)\n",
    "    plt.imshow(selected_images[n])\n",
    "    correct_prediction = true_labels[n] == predicted_labels[n]\n",
    "    color = \"darkgreen\" if correct_prediction else \"crimson\"\n",
    "    true_label_name = model.config.id2label[str(true_labels[n])]\n",
    "    predicted_label_name = model.config.id2label[str(predicted_labels[n])]\n",
    "    title = predicted_label_name if correct_prediction else \"{}\\n({})\".format(predicted_label_name, true_label_name) \n",
    "    plt.title(title, fontsize=14, color=color)\n",
    "    plt.axis('off')\n",
    "_ = plt.suptitle(\"ImageNet predictions\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a915b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
